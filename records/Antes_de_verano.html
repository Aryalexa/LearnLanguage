<!doctype html>
<html>
<head>
    <title>Antes de verano</title>

    <meta charset="utf-8" />
    <meta http-equiv="Content-type" content="text/html; charset=utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.1/css/bootstrap.min.css">
    <link rel="stylesheet" href="css/main.css">
    <link href='https://fonts.googleapis.com/css?family=Lato:400,300,700' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Lobster' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Dosis' rel='stylesheet' type='text/css'>

</head>

<body>

<div class="">
  <h2 class="font-dosis green">TFG</h2>

  ¿Cómo detectar la similitud de un audio de voz grabado con otro audio de voz?
  <br>
  <a href="http://stackoverflow.com/questions/17010516/how-to-detect-how-similar-a-speech-recording-is-to-another-speech-recording
">stack overflow -> how-to-detect-how-similar-a-speech-recording-is-to-another-speech-recording</a>

<p>
  A lot of people seem to be suggesting some sort of edit distance, which IMO is a totally wrong approach for determining the similarity of two speech patterns, especially for patterns as short as OP is implying.

  The specific algorithms used by speech-recognition in fact are nearly the opposite of what you would like to use here. The problem in speech recognition is resolving many similar pronunciations to the same representation. The problem here is to take a number of slightly different pronunciations and get some kind of meaningful distance between them.

  I've done quite a bit of this stuff for large scale data science, and while I can't comment on exactly how proprietary programs do it, I can comment on how it's done in academia and provide a solution that is straightforward and will give you the power and flexibility that you want for this approach.

  FIRSTLY: Assuming that what you have is some chunk of audio without any filtering done on it. Just as it would be acquired from a microphone. The first step is to eliminate background noise. There are a number of different methods for this, but I'm going to assume that what you want is something that will work well without being incredibly difficult to implement.

  * Filter the audio using scipy's filtering module here (<a href="http://docs.scipy.org/doc/scipy/reference/signal.html">signal</a>). There are a lot of frequencies that microphones pick up that are simply not useful for categorizing speech. I would suggest either a Bessel or a Butterworth filter to ensure that your waveform is persevered through filtering. The fundamental frequencies for everyday speech are generally between 800 and 2000 Hz (reference: http://en.wikipedia.org/wiki/Human_Voice ) so a reasonable cutoff would be something like 300 to 4000 Hz, just to make sure you don't lose anything.

  * Look for the least active portion of speech and assume that is a reasonable representation of background noise. At this point you're going to want to run a series of fourier transforms along your data (or generate a spectrogram) and find the part of your speech recording that has the lowest average frequency response. Once you have that snapshot, you should subtract it from all other points in your audio sample.

  * At this point you should have an audio file that is mostly just your user's speech and should be ready to be compared to another file that has gone through this process. Now, we want to actually clip the sound and compare this clip to some master clip.
</p>




  <hr>
  <h3 class="font-dosis green">DESARROLLO</h3>
  <hr>
<ol>
  <li>
    Grabar con android:
    <ul>
      <li>Alternativa 1: Usar clase AudioRecord: <a href="http://developer.android.com/reference/android/media/AudioRecord.html">link</a> (NO)
      </li>
      <li>Alternativa 2: Usar Audio Capture: <a href="http://developer.android.com/intl/es/guide/topics/media/audio-capture.html">link</a> , using the class MediaRecorder. Tenemos un bottom que graba y otro que reproduce. (HECHO sin probar).
      	se genera un .3gp.
      	configuraciones:
              mRecorder.setAudioSource(MediaRecorder.AudioSource.MIC);
              mRecorder.setOutputFormat(MediaRecorder.OutputFormat.THREE_GPP)
              mRecorder.setAudioEncoder(MediaRecorder.AudioEncoder.AMR_NB);
      </li>
      <li>Alternativa 3: <a href="https://www.youtube.com/watch?v=jcrh8C376-c">youtube vid</a> con mediaPlayer
      </li>
    </ul>
  </li>

  <li>
    Filtro<br>
      <p>alt 0: class equalizer o filtro de python</p>
      <p>alt 1:<br>
        Lo mejor que podemos usar es la biblioteca TarsosDSP:
        <a href="http://husk.eecs.berkeley.edu/courses/cs160-sp14/index.php/Sound_Programming">berkeley : sound programming</a>
        <br>
        Esta biblioteca tiene funciones para filtros, para la transformada de Fourier y
        para pintar el espectrograma, que es todo lo que nos interesa en los pasos que tenemos que dar ahora.
        Tienes los filtros en
        <a href="https://github.com/JorenSix/TarsosDSP/tree/71ae353871a75d916a642dbb7377fead9d175a68/src/core/be/tarsos/dsp/filters">filtros</a>
        Tienes un ejemplo de FFT y su dibujo a partir de la línea 197 de
        <a href="https://github.com/JorenSix/TarsosDSP/blob/master/src/examples/be/tarsos/dsp/example/Spectrogram.java">spectogram.java</a>
      </p>
  </li>

  <li>
    Filtrado* <br>
      - Test filters
      <a href="https://github.com/JorenSix/TarsosDSP/blob/bdf2c4ffcfee46a2a6bea07f9e634450692d7e1d/src/tests/be/tarsos/dsp/test/TestFilters.java">testFilters.java</a>
  </li>
</ol>

  <hr>
  <h4>abril - 1,2</h4>
  - TARSOS DSP descargar el .jar, añadir a libs
  <br>
  - grabar
  <br>
  - dibujar spectogram
  <br>
  -- la clase spectogram es un Jframe
  <br>
  -- hay que hacerlo en un activity dibujando una clase surfaceView que dibuja en un canvas (<a href="http://obviam.net/index.php/a-very-basic-the-game-loop-for-android/">a-very-basic-the-game-loop-for-android</a> , <a href="https://www.youtube.com/watch?v=Z2YogvILjvo">youtube vid</a>)
  <br>
  -- spectogram necesita un archivo => que formato de audio debe tener?
  <br>
  -- pasando de IU java a android.... como mostrar la imagen? bufferedimage?

  <hr>
  <h4>COSAS A TENER EN CUENTA</h4>

  *. Enabling On-device Developer Options <a href="http://developer.android.com/intl/es/tools/device.html">device.html</a>
  <br>
   Note: If you manually enable debugging in the manifest file, be sure to disable it in your release build (your published application should usually not be debuggable).
  <br>
  *.  speech recognition (<a href="https://www.youtube.com/watch?v=6G79QhBUvHk">youtube vid</a> )
  <br>
  text-to-speech
</div>

</body>
</html>
